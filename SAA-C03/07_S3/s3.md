# S3
- Amazon S3 사용 사례
  - 백업 및 저장
  - 재해 복구
  - 아카이브
  - 하이브리드 클라우드 저장소
  - 애플리케이션 호스팅
  - 미디어 호스팅
  - 데이터 레이크 및 대용량 데이터 분석
  - 소프트웨어 제공
  - 정적 웹 사이트
- 버킷
  - Amazon S3는 사람들이 "버킷" (디렉터리)에 객체 (파일)을 저장할 수 있게 합니다.
  - 버킷은 전체 지역 및 모든 계정을 통해 전역적으로 고유한 이름을 가져야 합니다.
  - 버킷은 지역 수준에서 정의됩니다.
  - S3는 글로벌 서비스처럼 보이지만 버킷은 특정 지역에 생성됩니다.
  - 네이밍 규칙
    - 대문자 없음, 언더스코어 없음
    - 3~63자 길이
    - IP가 아님
    - 소문자로 시작해야 함
    - 접두사 xn--로 시작하지 않아야 함
    - 접미사 -s3alias로 끝나면 안 됨
- 객체
  - 객체(파일)는 키(Key)를 가지고 있습니다.
  - 키는 전체 경로입니다:
    - s3://my-bucket/my_file.txt
    - s3://my-bucket/my_folder1/another_folder/my_file.txt
  - 키는 접두사(prefix)와 객체 이름으로 구성됩니다.
    - s3://my-bucket/my_folder1/another_folder/my_file.txt
  - 버킷 내에서 "디렉터리"라는 개념은 없습니다.(하지만 UI가 그렇게 보이게 만들 수 있습니다)
  - 단지 슬래시("/")를 포함한 아주 긴 이름의 키만 존재합니다.
  - 객체 값은 body의 내용입니다
    - 최대 객체 크기는 5TB (5000GB)입니다.
    - 5GB 이상 업로드하는 경우 "멀티파트 업로드"를 사용해야 합니다.
  - 메타데이터 (키/값 쌍의 텍스트 목록 - 시스템 또는 사용자 메타데이터)
  - 태그 (유니코드 키/값 쌍 - 최대 10개) - 보안/수명주기에 유용합니다.
  - 버전 ID (버전 관리가 활성화된 경우)
- 보안
  - 사용자 기반
    - IAM 정책 - 특정 사용자에 대해 허용되는 API 호출
  - 리소스 기반
    - 버킷 정책 - S3 콘솔에서 정의되는 버킷 전체 규칙 - 계정 간 허용
    - 객체 액세스 제어 목록 (ACL) - 더 세분화된 권한 설정 (비활성화 가능)
    - 버킷 액세스 제어 목록 (ACL) - 덜 일반적인 권한 설정 (비활성화 가능)
  - 참고: IAM 주체는 다음 조건을 충족하는 경우 S3 객체에 액세스할 수 있습니다.
    - 사용자 IAM 권한이 허용하거나 리소스 정책이 허용함
    - 그리고 명시적으로 거부되는 권한이 없음
  - 암호화: 암호화 키를 사용하여 Amazon S3의 객체를 암호화합니다.
- S3 버킷 정책
  - JSON 기반 정책
    - 리소스: 버킷 및 객체
    - 효과: 허용/거부
    - 동작: 허용 또는 거부할 API 세트
    - 주체: 정책을 적용할 계정 또는 사용자
  - S3 버킷 정책 사용 시 다음을 수행할 수 있습니다.
    - 버킷에 대한 공개 액세스 허용
    - 객체 업로드 시 암호화를 강제화
    - 다른 계정에 액세스 권한 부여 (계정 간 액세스)
- 버전 관리
  - Amazon S3에서 파일의 버전을 관리할 수 있습니다.
  - 버전 관리는 버킷 수준에서 활성화됩니다.
  - 동일한 키에 대한 덮어쓰기는 "버전"을 변경합니다(1, 2, 3...).
  - 버전 관리를 사용하는 것이 좋은 방법입니다.
    - 의도하지 않은 삭제로부터 보호됩니다(버전을 복원할 수 있음).
    - 이전 버전으로 쉽게 롤백할 수 있습니다.
  - 참고
    - 버전 관리를 활성화하기 전에 버전화되지 않은 파일은 "null" 버전을 가집니다.
    - 버전 관리를 일시 중지해도 이전 버전은 삭제되지 않습니다.
- 복제 (CRR 및 SRR)
  - 소스 버킷과 대상 버킷에서 버전 관리를 활성화해야 합니다.
  - 교차 지역 복제 (CRR)
  - 동일 지역 복제 (SRR)
  - 버킷은 다른 AWS 계정에 있을 수 있습니다.
  - 복사는 비동기적으로 수행됩니다.
  - S3에 적절한 IAM 권한을 부여해야 합니다.
  - 사용 사례
    - CRR - 규정 준수, 지연 시간 감소 액세스, 계정 간 복제
    - SRR - 로그 집계, 프로덕션 및 테스트 계정 간 실시간 복제
  - 참고
    - 복제를 활성화한 후에는 새로운 객체만 복제됩니다.
    - 선택적으로 S3 일괄 복제를 사용하여 기존 객체를 복제할 수 있습니다.
      - 기존 객체와 복제에 실패한 객체를 복제합니다.
    - 삭제 작업에 대해서는
      - 소스에서 대상으로 삭제 표시자를 복제할 수 있습니다 (선택적 설정).
      - 버전 ID가 있는 삭제는 복제되지 않습니다 (악의적인 삭제를 방지하기 위해).
    - 복제에는 "체이닝"이 없습니다.
      - 버킷 1이 버킷 2로 복제되고 버킷 2가 버킷 3로 복제되는 경우
      - 버킷 1에서 생성된 객체는 버킷 3으로 복제되지 않습니다.
- S3의 내구성과 가용성
  - 내구성
    - 다중 가용 영역을 통해 객체의 높은 내구성 (99.999999999%, 11 9) 보장
    - Amazon S3에 10,000,000개의 객체를 저장한 경우, 평균적으로 10,000년에 한 번의 객체 손실이 발생할 수 있습니다.
    - 모든 스토리지 클래스에 동일하게 적용됩니다.
  - 가용성
    - 서비스의 신속한 가용성을 측정하는 지표
    - 스토리지 클래스에 따라 다양하게 변동
    - 예: S3 표준은 99.99%의 가용성을 가지며, 연간 53분 동안 사용할 수 없는 상태입니다.
- S3 스토리지 클래스
  - Amazon S3 Standard - 일반 목적용
    - 99.99%의 가용성
    - 자주 액세스되는 데이터에 사용됩니다.
    - 지연 시간이 적고 처리량이 높습니다.
    - 2개의 동시 시설 장애를 견딜 수 있습니다.
    - 사용 사례: 대규모 데이터 분석, 모바일 및 게임 애플리케이션, 콘텐츠 배포 등
  - Amazon S3 Standard-Infrequent Access (IA) - 자주 액세스되지 않는 데이터용
    - 덜 자주 액세스되지만 필요할 때 빠른 액세스가 필요한 데이터에 사용됩니다.
    - S3 표준보다 낮은 비용
    - Amazon S3 표준-자주 액세스 (S3 표준-IA)
      - 99.9%의 가용성
      - 사용 사례: 재해 복구, 백업
    - Amazon S3 단일 가용 영역-자주 액세스 (S3 단일 가용 영역-IA)
      - 단일 가용 영역에서 높은 내구성 (99.999999999%)을 제공하며, 가용 영역이 파괴되면 데이터가 손실됩니다.
      - 99.5%의 가용성
      - 사용 사례: 온프레미스 데이터의 보조 백업 복사본 또는 재생 가능한 데이터 저장
  - Amazon S3 One Zone-Infrequent Access - 한 지역에 저장되는 자주 액세스되지 않는 데이터용
  - Amazon S3 Glacier 스토리지 클래스
    - 아카이빙 또는 백업을 위한 저렴한 객체 저장소입니다.
    - 가격: 저장소 가격 + 객체 검색 비용
  - Amazon S3 Glacier Instant Retrieval - 즉시 검색이 가능한 Glacier용
    - 밀리초 단위의 검색 속도로, 분기별로 액세스되는 데이터에 적합합니다.
    - 최소 저장 기간은 90일입니다.
  - Amazon S3 Glacier Flexible Retrieval - 유연한 검색이 가능(이전의 Amazon S3 Glacier)
    - Expedited (1분에서 5분), Standard (3시간에서 5시간), Bulk (5시간에서 12시간) - 무료
    - 최소 저장 기간은 90일입니다.
  - Amazon S3 Glacier Deep Archive - Deep Archive용 Glacier(장기 저장용)
    - Standard (12시간), Bulk (48시간)
    - 최소 저장 기간은 180일입니다.
  - Amazon S3 Intelligent Tiering - 자동으로 최적의 클래스로 이동하는 기능이 있는 클래스
    - 작은 월간 모니터링 및 자동 티어링 요금이 있습니다.
    - 사용량에 따라 자동으로 액세스 티어 간에 객체를 이동합니다.
    - S3 Intelligent-Tiering에서는 검색 요금이 부과되지 않습니다.
    - 자주 액세스 티어 (자동): 기본 티어
    - 가끔 액세스 티어 (자동): 30일 동안 액세스되지 않은 객체
    - 아카이브 즉시 액세스 티어 (자동): 90일 동안 액세스되지 않은 객체
    - 아카이브 액세스 티어 (선택 사항): 90일에서 700일 이상으로 구성 가능
    - 딥 아카이브 액세스 티어 (선택 사항): 180일에서 700일 이상으로 구성 가능
  - S3 Lifecycle 구성을 통해 수동 또는 자동으로 클래스 간 이동이 가능합니다.

# S3 Deep  
- 저장 클래스 간의 이동
  - 객체를 저장 클래스 간에 전환할 수 있습니다.
  - 사용 빈도가 낮은 객체는 Standard IA로 이동합니다.
  - 빠른 액세스가 필요하지 않은 아카이브 객체는 Glacier 또는 Glacier Deep Archive로 이동합니다.
  - 객체 이동은 Lifecycle Rules를 사용하여 자동화할 수 있습니다.
- Lifecycle Rules (수명 주기 규칙)
  - 전환 작업 - 객체를 다른 저장 클래스로 전환하도록 구성합니다.
    - 객체를 생성 후 60일이 지난 후 Standard IA 클래스로 이동합니다.
    - 6개월 후 아카이빙을 위해 Glacier로 이동합니다.
  - 만료 작업 - 일정 시간이 지난 후 객체를 만료시키고(삭제) 구성합니다.
    - 액세스 로그 파일은 365일 후에 삭제되도록 설정할 수 있습니다.
    - 버전 관리가 활성화된 경우 오래된 파일의 이전 버전을 삭제하는 데 사용할 수 있습니다.
    - 불완전한 멀티파트 업로드를 삭제하는 데 사용할 수 있습니다.
  - 특정 접두사(예: s3://mybucket/mp3/*)에 대해 규칙을 생성할 수 있습니다.
  - 특정 객체 태그(예: Department: Finance)에 대해 규칙을 생성할 수 있습니다.
- Storage Class Analysis (저장 클래스 분석)
  - 객체를 적절한 저장 클래스로 전환할 때 도움이 되는 분석 기능입니다.
  - Standard 및 Standard IA에 대한 권장 사항 제공
    - One-Zone IA 또는 Glacier에는 적용되지 않습니다.
  - 보고서는 매일 업데이트됩니다.
  - 데이터 분석 결과를 보기까지 24~48시간이 소요됩니다.
- 요청자 지불(Requester Pays)
  - 일반적으로 버킷 소유자는 버킷과 관련된 Amazon S3 저장 및 데이터 전송 비용을 모두 부담합니다.
  - 요청자 지불 버킷의 경우, 버킷 소유자 대신 요청자가 요청 및 버킷에서 데이터 다운로드의 비용을 지불합니다.
  - 다른 계정과 대용량 데이터셋을 공유하려는 경우 유용합니다.
  - 요청자는 AWS에서 인증되어야 하며 익명으로는 요청할 수 없습니다.
- S3 Event Notifications
  - S3:ObjectCreated, S3:ObjectRemoved, S3:ObjectRestore, S3:Replication...
  - 객체 이름 필터링 가능 (*.jpg 등)
  - 사용 사례: S3에 업로드된 이미지의 썸네일 생성
  - 원하는만큼 많은 "S3 이벤트"를 생성할 수 있음
  - S3 이벤트 알림은 일반적으로 몇 초 내에 이벤트를 전달하지만 때로는 1분 이상 소요될 수도 있음
- S3 Event Notifications with Amazon EventBridge
  - JSON 규칙을 사용한 고급 필터링 옵션 (메타데이터, 객체 크기, 이름 등)
  - 다중 대상 - Step Functions, Kinesis Streams / Firehose 등
  - EventBridge 기능 - 이벤트 아카이브, 이벤트 재생, 신뢰성 있는 전달
- S3 성능
  - 멀티파트 업로드
    - 파일 크기가 100MB보다 큰 경우 권장되며, 5GB보다 큰 파일의 경우 사용해야 함
    - 업로드를 병렬화하여 전송 속도를 높일 수 있음
  - S3 전송 가속
    - 파일을 AWS 엣지 위치로 전송하여 해당 위치에서 데이터를 대상 지역의 S3 버킷으로 전달하여 전송 속도를 증가시킴
    - 멀티파트 업로드와 호환됨
  - S3 바이트 범위 조회
    - 특정 바이트 범위를 요청하여 GET을 병렬화할 수 있음
    - 장애 발생 시 더 나은 내구성을 갖게 됨
- S3 Select 및 Glacier Select
  - 서버 측 필터링을 통해 SQL을 사용하여 더 적은 데이터를 검색합니다.
  - 행 및 열로 필터링 가능 (간단한 SQL 문 사용)
  - 네트워크 전송량이 적어지고 클라이언트 측의 CPU 비용이 줄어듭니다.
- S3 Batch Operations
  - 단일 요청으로 기존 S3 객체에 대해 대량 작업을 수행합니다.
    - 객체 메타데이터 및 속성 수정
    - S3 버킷 간에 객체 복사
    - 암호화되지 않은 객체 암호화
    - ACL 및 태그 수정
    - S3 Glacier에서 객체 복원
    - 각 객체에 대해 사용자 정의 작업을 수행하기 위해 Lambda 함수 호출
  - 작업은 객체 목록, 수행할 작업 및 선택적 매개변수로 구성됩니다.
  - S3 Batch Operations는 재시도를 관리하고 진행 상황을 추적하며 완료 알림을 보내며 보고서를 생성합니다.
  - 객체 목록을 가져오기 위해 S3 Inventory를 사용하고 객체를 필터링하기 위해 S3 Select를 사용할 수 있습니다.
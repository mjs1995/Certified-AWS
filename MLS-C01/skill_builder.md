# Exam Readiness: AWS Certified Machine Learning - Specialty
- 데이터 엔지니어링
  - AWS Lake Formation 및 Amazon S3
    - AWS Lake Formation은 데이터 레이크 솔루션이며, Amazon S3는 AWS에서의 데이터 과학 처리용으로 많이 사용되는 스토리지 옵션입니다.
  - Amazon S3와 Amazon SageMaker
    - Amazon SageMaker를 사용하여 기계 학습 모형을 훈련하는 동안 Amazon S3를 사용할 수 있습니다. Amazon S3는 Amazon SageMaker와 통합되어 훈련 데이터와 모형 훈련 결과를 저장합니다.
  - Amazon FSx for Lustre
    - 훈련 데이터가 이미 Amazon S3에 있고 다른 알고리즘과 파라미터를 사용하여 훈련 작업을 여러 번 실행할 계획이라면 파일 시스템 서비스인 Amazon FSx for Lustre를 사용하는 것이 좋습니다. 
    - FSx for Lustre는 Amazon SageMaker에 Amazon S3 데이터를 제공하여 훈련 작업을 가속화합니다. 
    - 훈련 작업을 처음 실행할 때 FSx for Lustre는 Amazon S3의 데이터를 자동으로 복사하여 Amazon SageMaker에서 사용할 수 있도록 합니다. 
    - 훈련 작업의 후속 반복에 동일한 Amazon FSx 파일 시스템을 사용함으로써 공통 Amazon S3 객체를 반복해서 다운로드하는 것을 방지할 수 있습니다.
  - Amazon S3와 Amazon EFS
    - 훈련 데이터가 이미 Amazon Elastic File System(EFS)에 있는 경우 이를 훈련 데이터 소스로 사용하는 것이 좋습니다. 
    - Amazon EFS는 데이터 이동 없이 서비스에서 훈련 작업을 바로 시작할 수 있으므로 더 빨리 훈련을 시작할 수 있습니다. 데이터 과학자가 Amazon EFS에 홈 디렉터리를 가지고 있어서 새로운 데이터를 가져오고 동료와 데이터를 공유하고 데이터 집합에 다양한 필드 또는 레이블을 추가하는 실험을 통해 모형을 빠르게 반복하는 환경에서는 흔히 있는 일입니다
  - 데이터 수집의 두 가지 유형인 배치 처리와 스트림 처리
    - 배치 처리
      - 배치 처리에서는 주기적으로 소스 데이터를 수집하고 그룹화함
        - 배치 처리를 통해 수집 계층은 정기적으로 소스 데이터를 수집 및 그룹화하여 Amazon S3와 같은 대상으로 전송합니다. 
        - 논리적 순서, 특정 조건의 활성화 또는 간단한 일정에 따라 그룹을 처리할 수 있습니다. 
        - 배치 처리는 일반적으로 다른 수집 옵션보다 경제적으로 쉽게 구현되기 때문에 실시간 또는 거의 실시간에 가까운 데이터가 필요하지 않은 경우에 사용됩니다.
      - AWS 클라우드로의 배치 처리를 지원하는 여러 서비스
        - AWS 클라우드로의 배치 수집에는 데이터를 분류, 정리 및 보강하고 다양한 데이터 스토어 간에 이동하는 데 사용할 수 있는 ETL(추출, 변환 및 로드) 서비스인 AWS Glue와 같은 서비스를 이용할 수 있습니다. 
        - AWS Database Migration Service(AWS DMS)는 배치 수집을 지원하는 또 다른 서비스입니다. 이 서비스는 지정한 간격으로 관계형 데이터베이스 관리 시스템, 데이터 웨어하우스 및 NoSQL 데이터베이스와 같은 소스 시스템에서 기록 데이터를 읽습니다. 
        - AWS Step Functions를 사용하여 복잡한 워크플로와 관련된 다양한 ETL 작업을 자동화할 수 있습니다.
    - 스트림 처리
      - 스트림 처리에서는 인식되는 대로 데이터 조작 및 로드
        - 실시간 처리를 포함하는 스트림 처리에는 그룹화가 전혀 포함되지 않습니다. 
        - 데이터가 생성되거나 데이터 수집 계층에서 인식되는 즉시 소싱되고 조작되고 로드됩니다. 이러한 종류의 수집은 시스템이 소스를 지속적으로 모니터링하고 새로운 정보를 수용해야 하므로 경제성이 떨어집니다. 
        - Amazon SageMaker 엔드포인트를 사용하여 웹 사이트에서 고객에게 표시하려는 실시간 예측이나, 실시간 대시보드와 같이 지속적으로 새로 고쳐지는 데이터가 필요한 실시간 분석에 사용하려 할 수 있습니다.
      - Amazon Kinesis는 AWS에서 데이터를 스트리밍하기 위한 플랫폼
        - AWS에서 데이터를 스트리밍하기 위한 플랫폼인 Amazon Kinesis를 사용하여 빠르게 이동하는 데이터를 캡처하고 수집하는 것이 효과적입니다. 
        - Amazon Kinesis는 특수한 요구 사항에 맞는 맞춤형 스트리밍 데이터 애플리케이션을 구축할 수 있는 기회를 제공하며, 스트리밍 데이터를 보다 쉽게 로드하고 분석하는 데 중점을 둔 여러 서비스를 제공합니다.
  - 데이터 변환 솔루션 식별 및 구현
    - 수집된 원시 데이터는 기계 학습에 사용할 수 없음
      - 데이터 중복 제거, 불완전한 데이터 관리 및 속성 표준화를 비롯한 데이터 변환 및 정리 단계를 거쳐야 합니다. 
      - 데이터 변환에서는 필요에 따라 데이터의 쿼리를 용이하게 하기 위해 보통 OLAP 모형으로 데이터 구조를 변경할 수 있습니다. 
    - 기계 학습을 위한 데이터 변환
      - MapReduce 및 Apache Spark와 같은 분산 컴퓨팅 프레임워크는 데이터 처리와 노드 작업 배포 및 관리를 위한 프로토콜을 제공합니다. 
      - 알고리즘을 사용하여 데이터 집합을 하위 집합으로 분할하고 컴퓨팅 클러스터의 노드에 분산합니다.
    - Amazon EMR에서 Apache Spark를 사용하여 관리형 프레임워크 구축
      - Amazon EMR에서 Apache Spark를 사용하면 방대한 양의 데이터를 처리할 수 있는 관리형 프레임워크가 구축됩니다. 
      - Amazon EMR은 HPC(고성능 컴퓨팅) 애플리케이션에 적합하도록 향상된 네트워크 성능과 그에 비례하는 높은 CPU 성능을 제공하는 다양한 인스턴스 유형을 지원합니다.
    - 기계 학습을 위한 데이터 변환의 핵심 단계는 데이터 집합을 분할하는 것입니다.
      - 기계 학습 애플리케이션에 필요한 데이터 집합은 데이터베이스 웨어하우스, 스트리밍 IoT 입력 또는 중앙 집중식 데이터 레이크에서 가져옵니다
      - ETL 처리 서비스(Amazon Athena, AWS Glue, Amazon Redshift Spectrum)는 기능을 보완하며, Amazon S3에 저장되거나 Amazon S3를 대상으로 하는 데이터 집합을 사전 처리하도록 구축할 수 있습니다
      - Athena 및 Amazon Redshift Spectrum 같은 서비스로 데이터를 변환하는 것 외에 AWS Glue와 같은 서비스를 사용하여 메타데이터 검색 및 관리 기능을 제공할 수도 있습니다
    - Amazon S3에 단일 데이터 소스를 저장하고 임시 분석을 수행할 수 있습니다.
      - 고객은 Amazon S3에 단일 데이터 소스를 저장하고 Athena를 사용하여 임시 분석을 수행하고, Amazon Redshift의 데이터 웨어하우스와 통합하고, Amazon QuickSight를 사용하여 지표를 보여주는 시각적 대시보드를 구축하며, Amazon SageMaker를 사용하여 재입원을 예측하는 기계 학습 모형을 구축할 수 있습니다. 데이터를 이동하지 않고 다양한 서비스를 사용하여 데이터에 연결함으로써 고객은 동일한 데이터의 중복 복사본을 만들지 않아도 됩니다.
      - ![image](https://github.com/mjs1995/Certified-AWS/assets/47103479/2a8326f8-5bc7-4be6-b26a-56b8b2185b73)
- 탐색적 데이터 분석
  - 일반적으로 사용되는 척도화 및 정규화 변환 모음
    - 평균/분산 표준화
    - MinMax 척도화
    - Maxabs 척도화
    - 로버스트 척도화
    - 정규화
  - 시각화를 통해 특정 특성을 더 잘 파악
    - 데이터의 범위는 어떻게 됩니까?
    - 데이터의 최고점은 얼마입니까?
    - 특이치가 있습니까?
    - 데이터에 흥미로운 패턴이 있습니까?
- 모형화
  - NLP 및 CV를 위한 Amazon SageMaker 기본 제공 알고리즘
    - NLP(자연어 처리)를 위한 알고리즘
      - 자연어 처리를 위한 Amazon SageMaker의 기본 제공 알고리즘이 있습니다.
      - BlazingText 알고리즘은 Word2Vec 및 텍스트 분류 알고리즘의 고도로 최적화된 구현을 제공합니다.
      - Sequence2Sequence는 일련의 토큰(예: 텍스트, 오디오)을 입력으로 사용하고 또 다른 토큰 시퀀스를 출력으로 생성하는 지도 학습 알고리즘입니다.
      - Object2Vec은 Amazon SageMaker BlazingText 알고리즘에 최적화된 단어를 임베딩하는 유명한 Word2Vec 기법을 일반화합니다.
  - CV(컴퓨터 비전)을 위한 알고리즘
    - 컴퓨터 비전을 위한 Amazon SageMaker 기본 제공 알고리즘이 있습니다.
      - 이미지 분류는 이미지를 분류하는 데 사용되는 지도 학습 알고리즘입니다.
      - 물체 감지 알고리즘은 단일 심층 신경망을 사용하여 이미지의 물체를 감지하고 분류합니다. 이 알고리즘은 입력으로 이미지를 가져와 이미지 장면 내에서 객체의 모든 인스턴스를 식별하는 지도 학습 알고리즘입니다. 객체는 지정된 모음 내 클래스 중 하나로 범주화되는데, 이때 해당 클래스에 속하는 신뢰도 점수를 사용합니다. 이미지에서 해당 위치와 척도는 사각형 경계 상자로 표시됩니다.
      - 의미 체계 세분화 알고리즘은 미리 정의된 클래스 집합의 클래스 레이블로 이미지의 모든 픽셀에 태깅합니다.
  - 기타 훈련 알고리즘 옵션
    - Amazon SageMaker에서 Apache Spark 사용
    - 사용자 지정 코드를 제출하여 TensorFlow 또는 Apache MXNet 같은 딥 러닝 프레임워크로 모형 훈련
    - 자체 사용자 지정 알고리즘을 사용하고 코드를 Docker 이미지에 포함
    - AWS Marketplace에서 알고리즘 구독
  - 하이퍼 파라미터
    - 하이퍼파라미터는 훈련 작업을 실행하기 전에 튜닝하여 기계 학습 알고리즘의 동작을 제어할 수 있는 노브 또는 설정입니다. 하이퍼파라미터는 훈련 시간, 모형 수렴 및 모형 정확도와 관련이 있으므로 모형 훈련에 큰 영향을 미칠 수 있습니다. 훈련 작업에서 파생되는 모형 파라미터와 달리 하이퍼파라미터 값은 훈련 중에 변경되지 않습니다.
      - 모형 하이퍼파라미터
        - 모형 자체(필터 크기, 풀링, 스트라이드, 패딩과 같은 신경망 아키텍처의 속성)를 정의합니다.
      - 옵티마이저 하이퍼파라미터
        - 모형이 데이터를 기반으로 패턴을 학습하는 방법과 관련된 유형으로, 신경망 모형에 사용됩니다.
        - 경사 하강법 및 확률적 경사 하강법 같은 옵티마이저, Adam과 같은 모멘텀을 사용하는 옵티마이저, Xavier 초기화 또는 He 초기화와 같은 방법을 사용하여 파라미터 가중치를 초기화하는 옵티마이저를 포함합니다.
      - 데이터 하이퍼파라미터
        - 데이터의 속성과 관련이 있으며, 데이터가 충분하지 않거나 데이터 변형(자르기, 크기 조정과 같은 데이터 증가 기법)이 충분하지 않을 때 자주 사용됩니다.
- 기계 학습 구현 및 운영
  - 고가용성 및 내결함성
    - 고가용성 솔루션에서는 아키텍처의 구성 요소가 작동을 멈추더라도 시스템이 계속 작동합니다. 고가용성의 중요한 측면 중 하나인 내결함성이 아키텍처에 내장되어 있으면 아키텍처의 구성 요소가 완전히 고장 나더라도 성능 저하 없이 애플리케이션이 계속해 실행되도록 보장합니다.
  - API 호출 및 관련 이벤트를 캡처하는 AWS CloudTrail
    - AWS CloudTrail은 AWS 계정에서 수행하거나 AWS 계정을 대신하여 수행한 API 호출 및 관련 이벤트를 캡처하고 사용자가 지정한 Amazon S3 버킷에 로그 파일을 전송합니다.
    - AWS를 호출한 사용자와 계정, 호출이 이루어진 소스 IP 주소, 호출이 발생한 시간을 파악할 수 있습니다.
  - 주요 AWS 서비스 및 기능을 활용하여 개별 구성 요소의 장애를 설계할 수 있음
    - AWS Glue와 AWS EMR
      - ETL 프로세스를 기계 학습 파이프라인과 분리해야합니다. 기계 학습에 필요한 컴퓨팅 파워는 ETL 프로세스에 필요한 것과 동일하지 않습니다. 요구 사항이 매우 다릅니다.
      - ETL 프로세스에서는 여러 형식의 파일을 읽고 필요에 따라 변환한 다음 영구 스토리지에 다시 기록해야 합니다. 읽기와 쓰기는 많은 메모리와 디스크 I/O를 필요로 하므로 ETL 프로세스를 분리할 때 대량의 ETL 데이터를 쉽게 처리할 수 있는 Apache Spark와 같은 프레임워크를 사용합니다.
      - 반면, 훈련에는 훈련 요구 사항을 처리하는 데 CPU보다 훨씬 더 적합한 GPU가 필요할 수 있습니다. 그러나 GPU는 모형이 훈련되지 않을 때 계속 실행하기에는 경제성이 떨어집니다. 따라서 AWS Glue 또는 Amazon EMR과 같은 ETL 서비스를 사용하기만 하면 이 분리된 아키텍처를 사용할 수 있습니다. ETL 서비스는 ETL 작업에 Apache Spark를 사용하고 Amazon SageMaker를 사용하여 모형을 훈련, 테스트 및 배포합니다.
    - Amazon SageMaker 엔드포인트
      - 고가용성 기계 학습 서비스 엔드포인트를 보장하려면 가용 영역 전체에 걸쳐 여러 인스턴스로 지원되는 Amazon SageMaker 엔드포인트를 배포하십시오.
    - Amazon SageMaker
      - Amazon SageMaker를 사용하면 훈련 및 추론 모두를 위한 기계 학습 모형을 손쉽게 컨테이너식으로 만들 수 있습니다. 그 과정에서 소결합된 분산 서비스로 구성된 기계 학습 모형을 생성하고 원하는 수의 플랫폼에 배치하거나 애플리케이션이 분석하고 있는 데이터 가까이에 배치할 수 있습니다.
    - AWS Auto Scaling
      - AWS Auto Scaling을 사용하면 애플리케이션으로 전송되는 트래픽의 변화에 대응하여 애플리케이션의 일부인 Amazon SageMaker 엔드포인트 등의 AWS 리소스에 대한 Auto Scaling을 구성함으로써 확장 가능한 솔루션을 구축할 수 있습니다.
      - AWS Auto Scaling을 사용하면 확장 조정 계획을 통해 리소스에 대한 확장 조정을 구성하고 관리할 수 있습니다. 조정 계획은 동적 조정과 예측 조정을 사용하여 애플리케이션의 리소스를 자동으로 조정합니다.
  - Amazon SageMaker에 통합된 보안 기능
    - 인증 - IAM 연동
    - 통찰력 확보 - IAM 정책 및 조건 키로 액세스 제한
    - 감사
      - AWS CloudTrail에 대한 API 로그
      - InvokeEndpoint 예외
    - 저장된 데이터 보호
      - AWS KMS 기반 암호화
        - 노트북
        - 훈련 작업
        - modelsEndpoint를 저장할 Amazon S3 위치
    - 데이터 보호 작동 방식
      - HTTPS
        - API/콘솔
        - 노트북
        - VPC 지원
        - 인터페이스 인터페이스
        - IPTraining 작업/엔드포인트별 제한
    - 규정 준수 프로그램
      - BAA
      - ISO 적격 PCI
      - DSS HIPAA
  - 기계 학습 솔루션 배포 및 운영
    - 엔드 투 엔드 테스트 및 A/B 테스트
    - API 버전 관리(여러 버전의 모형이 사용되는 경우)
    - 안정성 및 장애 조치
    - 지속적인 유지 관리
    - CI/CD(지속적 통합/지속적 배포)와 같은 클라우드 인프라 모범 사례
  - Amazon SageMaker 호스팅 서비스를 사용하여 모형을 배포하는 프로세스는 3단계 프로세스입니다.
    - Amazon SageMaker에서 모형 생성
      - 필요한 사항
        - 모형 아티팩트가 저장되는 Amazon S3 경로
        - 추론 코드가 포함된 이미지의 Docker 레지스트리 경로
        - 후속 배포 단계에 사용할 수 있는 이름
    - HTTPS 엔드포인트의 엔드포인트 구성 생성
      - 필요한 사항
        - 프로덕션 변형의 하나 이상의 모형 이름
        - Amazon SageMaker가 각 프로덕션 변형을 호스트하기 위해 시작하도록 하려는 기계 학습 컴퓨팅 인스턴스 프로덕션에서 모형을 호스팅할 때 엔드포인트를 구성하여 배포된 기계 학습 컴퓨팅 인스턴스를 탄력적으로 크기 조정할 수 있습니다.
    - HTTPS 엔드포인트 생성
      - 엔드포인트 구성을 Amazon SageMaker에 제공해야 합니다. 그러면 이 서비스가 기계 학습 컴퓨팅 인스턴스를 시작하고 구성에 지정된 대로 하나 이상의 모형을 배포합니다.
  - 기계 학습 모형을 프로덕션 환경에 제공할 때 주의 사항
    - 소프트웨어 엔지니어링 원칙을 적용합니다. 오류 복구 코드를 추가하고 예기치 않은 데이터 입력에 대한 테스트가 있는지 확인합니다. 다른 시스템에 대해 수행되는 단위 테스트, 품질 보증 및 사용자 수락 테스트와 동일한 종류의 테스트를 수행합니다. 기계 학습 시스템이 연구 단계에서 개발 단계로 진행된 경우, 이러한 권장 소프트웨어 엔지니어링 방식 중 일부가 일관되게 적용되었을 수 있습니다. AWS CodeBuild 및 AWS CodeCommit과 같은 일반적인 DevOps 도구를 사용하여 이 시스템을 자동화합니다.
    - 데이터 원본의 변경 사항을 추적, 식별 및 처리합니다. 데이터는 시간이 지남에 따라 변경될 수 있습니다. 단일 소스에서 데이터 유형을 변경하면 전체 파이프라인이 손상될 수 있습니다. 데이터 원본을 생성하는 소프트웨어가 변경될 경우 연쇄적인 영향을 미칠 수 있습니다.
    - 결과에 대한 지속적인 모니터링 및 평가를 수행합니다. 기계 학습 시스템의 결과를 기대치와 비교해 평가합니다. 프로젝트의 기대치에 대한 오류율 및 오류의 클래스를 확인하는 방법을 구축합니다. 전체 오류율이 동일한 경우, 여러 오류 등급의 비율이 동일합니까? 모형 드리프트가 발생합니까?
    - 향후 모형을 개선하는 데 사용할 수 있는 프로덕션 추론에서 데이터를 수집하는 방법을 만듭니다.
  - Amazon CloudWatch 지표를 사용하는 척도화 정책 정의 및 적용
    - Auto Scaling은 정책을 사용하여 실제 워크로드에 따라 인스턴스 수를 늘리거나 줄임
    - AWS Management Console을 사용하여 미리 정의된 지표에 따라 척도화 정책을 적용할 수 있음
    - 미리 정의돈 지표는 열거형에 정의되어 있으므로 코드에서 이름으로 지정하거나 콘솔에서 사용할 수 있음
    - 항상 Auto Scaling 구성을 로드 테스트하여 프로덕션 트래픽을 관리하는 데 사용하기 전에 올바르게 작동하는지 확인
  - 서비스 FAQ
    - 다음은 기계 학습 관련 AWS 서비스에 대한 이해도를 높이는 데 유용한 정보를 제공하는 서비스 FAQ의 링크입니다.
    - [AWS SageMaker FAQ](https://aws.amazon.com/ko/sagemaker/faqs/)
    - [AWS Comprehend FAQ](https://aws.amazon.com/ko/comprehend/faqs/)
    - [AWS Lex FAQ](https://aws.amazon.com/ko/lex/faqs/)
    - [AWS Polly FAQ](https://aws.amazon.com/ko/polly/faqs/)
    - [AWS Rekognition FAQ](https://aws.amazon.com/ko/rekognition/faqs/)
    - [AWS Translate FAQ](https://aws.amazon.com/ko/translate/faqs/)
    - [AWS Transcribe FAQ](https://aws.amazon.com/ko/transcribe/faqs/)
    - [AWS DeepLens FAQ](https://aws.amazon.com/ko/deeplens/faqs/)
  - AWS 블로그
    - [AWS Machine Learning 블로그](https://aws.amazon.com/ko/blogs/machine-learning/)

# AWS Sagemaker FAQ
- 지도 학습
  - SageMaker Amazon은 분류 또는 회귀 문제에 사용할 수 있는 몇 가지 내장된 범용 알고리즘을 제공합니다.
  - AutoGluon-표 형식 - 모델을 앙상블하고 여러 레이어로 쌓아 승계하는 오픈 소스 AutoML 프레임워크.
  - CatBoost - 그라디언트 부스트 트리 알고리즘의 구현으로, 순서가 있는 부스팅과 범주형 특성 처리를 위한 혁신적인 알고리즘의 구현.
  - Factorization Machine 알고리즘 - 고차원 저밀도 데이터 세트 내 특성 간 상호 작용을 경제적으로 캡처하도록 설계된 선형 모델의 확장.
  - K-Nearest Neighbors(k-NN) 알고리즘 - 레이블이 지정된 가장 가까운 k개의 포인트를 사용하여 분류할 새 데이터 포인트에 레이블을 할당하거나 회귀를 위해 가장 가까운 k개의 포인트 평균을 바탕으로 예측된 대상 값을 지정하는 비모수적 방법.
  - LightGBM - 효율성과 확장성을 개선하기 위한 두 가지 새로운 기법인 그라디언트 기반 단측 샘플링(GOSS)과 배타적 특성 번들링(EFB)이 추가된 그라디언트 부스트 트리 알고리즘의 구현.
  - 선형 학습자 알고리즘 - 회귀를 위한 선형 함수 또는 분류를 위한 선형 임계값 함수를 학습합니다.
  - TabTransformer—Transformer를 기반으로 구축된 새로운 딥 테이블 형식 데이터 모델링 아키텍처. self-attention-based
  - XGBoost 알고리즘 - 더 간단하고 약한 모델 세트의 예상치 앙상블을 결합하는 그라디언트 부스트 트리 알고리즘의 구현.
  - SageMaker 또한 Amazon은 기능 엔지니어링 및 시계열 데이터로부터 예측을 수행하는 동안 보다 전문화된 작업에 사용되는 몇 가지 내장된 지도 학습 알고리즘을 제공합니다.
  - Object2Vec 알고리즘 - 특성 추출에 사용되는 고도로 사용자 지정이 가능한 새로운 다목적 알고리즘. 고차원 객체의 저차원 밀도 임베딩을 학습하여 다운스트림 모델의 훈련 효율성을 향상시키는 특성을 생성할 수 있습니다. 이 알고리즘은 훈련에 레이블이 지정된 데이터가 필요하기 때문에 지도 알고리즘이지만, 사람의 명시적인 주석 없이 데이터의 자연스러운 클러스터링을 통해서만 관계 레이블을 얻을 수 있는 시나리오가 많이 있습니다.
  - DeepAR Forecasting 알고리즘 - 반복 신경망(RNN)을 사용하여 스칼라(1차원) 시계열을 예상하는 지도 학습 알고리즘.
- 비지도 학습
  - SageMaker Amazon은 클러스터링, 차원 축소, 패턴 인식 및 이상 탐지와 같은 다양한 비지도 학습 작업에 사용할 수 있는 여러 내장 알고리즘을 제공합니다.
  - Principal Component Analysis(PCA) 알고리즘 - 처음 몇 개의 주요 구성 요소에 데이터 포인트를 프로젝션하여 데이터 세트 내의 차원(특성 수)을 줄입니다. 목표는 가능한 한 많은 정보나 변형을 유지하는 것입니다. 수학자의 경우 주요 구성 요소은 데이터 공분산 행렬의 고유벡터입니다.
  - k-means 알고리즘 - 데이터 내 별도의 그룹화를 찾습니다. 이 경우 그룹의 멤버는 가급적 다른 멤버와 유사하고 다른 그룹의 멤버와는 가급적 다릅니다.
  - IP Insights - IPv4 주소의 사용 패턴을 학습합니다. IPv4 주소와 여러 엔터티(예: 사용자 ID 또는 계정 번호) 간 연결을 캡처하도록 설계되어 있습니다.
  - Random Cut Forest(RCF) 알고리즘 - 데이터 세트 내에서 제대로 구조화되거나 패턴이 있는 데이터와 다른 비정상적인 데이터 포인트를 탐지합니다.
- 텍스트 분석
  - SageMaker 자연어 처리, 문서 분류 또는 요약, 주제 모델링 또는 분류, 언어 전사 또는 번역에 사용되는 텍스트 문서의 분석에 맞게 조정된 알고리즘을 제공합니다.
  - BlazingText 알고리즘 - 대규모 데이터 세트로 쉽게 확장할 수 있는 Word2vec 및 텍스트 분류 알고리즘의 고도로 최적화된 구현. 많은 다운스트림 자연어 처리 (NLP) 태스크에 유용합니다.
  - Latent Dirichlet Allocation(LDA) 알고리즘 - 여러 문서에서 주제를 결정하는 데 적합한 알고리즘. 비지도 알고리즘으로 훈련 중 답이 포함된 예제 데이터를 사용하지 않습니다.
  - Neural Topic Model(NTM) 알고리즘 - 신경망 접근 방식을 사용하여 여러 문서에서 주제를 결정하는 또 다른 비지도 기법.
  - 텍스트 분류 - TensorFlow - 텍스트 분류에 사용할 수 있는 사전 훈련된 모델을 사용하여 학습 전송을 지원하는 지도 알고리즘.
- 이미지 처리
  - SageMaker 또한 이미지 분류, 객체 감지 및 컴퓨터 비전에 사용되는 이미지 처리 알고리즘도 제공합니다.
  - 이미지 분류 - MXNet - 답이 포함된 예제 데이터를 사용합니다(지도 알고리즘이라고 함). 이 알고리즘을 사용하여 이미지를 분류할 수 있습니다.
  - 이미지 분류 - TensorFlow—사전 훈련된 TensorFlow Hub 모델을 사용하여 특정 작업에 맞게 미세 조정합니다 (감독형 알고리즘이라고 함). 이 알고리즘을 사용하여 이미지를 분류할 수 있습니다.
  - 의미 체계 분할 알고리즘 - 컴퓨터 비전 응용 분야를 개발하는 데 세분화된 픽셀 수준 접근 방식을 제공합니다.
  - 객체 감지 - MXNet - 단일 심층 신경망을 사용하여 이미지의 물체를 감지하고 분류합니다. 이 알고리즘은 입력으로 이미지를 가져와 이미지 장면 내에서 객체의 모든 인스턴스를 식별하는 지도 학습 알고리즘입니다.
  - 물체 감지 - TensorFlow - 이미지에서 경계 상자와 객체 레이블을 감지합니다. 사용 가능한 사전 훈련된 모델을 사용하여 전이 학습을 지원하는 지도 학습 알고리즘입니다.

# Low-Code Machine Learning on AWS
- ML 기본 사항
  - 지도 학습
    - 회귀
      - 회귀에서 문제는 연속 값을 예측하는 것입니다. 수치(독립 변수)와 출력(종속 변수) 간 관계를 이해하기 위한 여러 다양한 방법을 사용할 수 있습니다.
      - 선형 회귀는 지정된 독립 변수 값에 대해 종속 변수 값을 예측하는 데 사용됩니다. 데이터 포인트 그래프에 맞춰진 직선을 사용합니다.
      - 의사결정 트리는 여러 관찰 결과에 대한 결론을 도출하기 위한 예측 모델로 사용됩니다.
      - 랜덤 포레스트는 대규모 의사결정 트리 모음입니다. 회귀 태스크의 경우 개별 트리의 평균 예측이 반환됩니다.
      - 신경망회귀는 인공 신경망이 연속 숫자 값을 모델링하고 예측하는 데 사용되는 기법입니다.
    - 분류
      - 분류에서 문제는 항목이 특정 범주 또는 클래스에 속한다고 예측하는 것입니다. 특정 입력 데이터 예제에 대해 클래스 레이블이 예측되는 다른 예측 모델링을 사용할 수 있습니다.
      - 로지스틱 회귀는 지정된 독립 변수 데이터 집합을 기준으로 이벤트가 발생할 가능성을 예측하는 데 사용됩니다. 일반적으로 예측은 1 또는 0, yes 또는 no, true 또는 false, 긍정 또는 부정과 같은 이진 출력을 나타냅니다.
      - 서포트 벡터 머신은 분류 및 회귀 분석을 위해 데이터를 분석하는 학습 알고리즘이 연결된 지도 학습 모델입니다.
      - 나이브 베이즈는 이벤트의 가능성을 설명하는 알고리즘으로, Thomas Bayes의 이름을 딴 베이즈의 정리를 기준으로 하는 알고리즘입니다. 지정된 해당 클래스 변수 값에 대해 모든 수치 쌍 간의 조건부 독립성에 대한 나이브 가정을 수행합니다.
